{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# autoreload imports\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misinformation detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard path wrangling to be able to import project config and sources\n",
    "import os\n",
    "import sys\n",
    "root = os.path.dirname(os.getcwd())\n",
    "sys.path.append(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# built-in\n",
    "import json\n",
    "import logging\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "# installed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# custom\n",
    "from src.utils.jupyter_setup import setup_jupyter\n",
    "from src.utils.rand_utils import RandUtils\n",
    "from src.utils.config_loader import ConfigLoader\n",
    "from src.utils.file_utils import FileUtils\n",
    "from src.data.path_manager import PathManager\n",
    "from src.data.data_loader import DataLoader\n",
    "from src.data.dataset_wrapper import DatasetWrapper\n",
    "from src.data.data_splitter import DataSplitter\n",
    "from src.evaluation.metrics import Metrics\n",
    "from src.features.bow_vectorizer import BowVectorizer\n",
    "\n",
    "# models\n",
    "from src.models.mnb import MNB\n",
    "from src.models.bnb import BNB\n",
    "from src.models.svm import SVM\n",
    "from src.models.lr import LR\n",
    "from src.models.gb import GB\n",
    "from src.models.cnn import CNN\n",
    "from src.models.rnn import RNN\n",
    "from src.models.lstm import LSTM\n",
    "\n",
    "# trainers\n",
    "from src.models.lr_torch import LRTorch\n",
    "from src.trainers.lr_trainer import LRTrainer\n",
    "from src.trainers.cnn_trainer import CNNTrainer\n",
    "from src.trainers.rnn_trainer import RNNTrainer\n",
    "from src.trainers.lstm_trainer import LSTMTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/PaxtonEdgar/Documents/InfEco/COVIDmisinfoBursts/Original_misinfo/config.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-d92d28de5175>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msetup_jupyter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWARNING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/InfEco/COVIDmisinfoBursts/Original_misinfo/src/utils/jupyter_setup.py\u001b[0m in \u001b[0;36msetup_jupyter\u001b[0;34m(root_dir, config_path, logging_level)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \"\"\"\n\u001b[1;32m     31\u001b[0m     \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mcfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConfigLoader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Config loaded.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     setup_logging(\n",
      "\u001b[0;32m~/Documents/InfEco/COVIDmisinfoBursts/Original_misinfo/src/utils/config_loader.py\u001b[0m in \u001b[0;36mload_config\u001b[0;34m(config_path)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mconfig_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConfigLoader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_project_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp_in\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0mcfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/PaxtonEdgar/Documents/InfEco/COVIDmisinfoBursts/Original_misinfo/config.json'"
     ]
    }
   ],
   "source": [
    "cfg = setup_jupyter(root, logging_level=logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_mgr = PathManager(cfg, root)\n",
    "data_df = pd.read_csv(path_mgr.processed_file_path('fc_cleaned.csv'))\n",
    "print('Documents retrieved:', len(data_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandUtils.set_random_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct X and y arrays from true and false labels\n",
    "valid_labels = ['true', 'false/misleading']\n",
    "label_filter = data_df['fact_new'].isin(valid_labels)\n",
    "X = data_df[label_filter]['subject']\n",
    "y = np.array([valid_labels.index(topic) for topic in data_df[label_filter]['fact_new']])\n",
    "\n",
    "# make sure positive and negative classes are balanced\n",
    "max_cls_count = sum(y == 0)\n",
    "random_indices = np.random.choice(sum(y == 1), max_cls_count, replace=False)\n",
    "X_misinfo = list(X[y == 1])\n",
    "y_misinfo = list(y[y == 1])\n",
    "X = np.concatenate((X[y == 0], [X_misinfo[i] for i in random_indices]))\n",
    "y = np.concatenate((y[y == 0], [y_misinfo[i] for i in random_indices]))\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = DataSplitter(n_splits=5, random_state=0)\n",
    "splits = {idx: split for idx, split in enumerate(ds.get_split_ids(X, y))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    'models/config/gb/gb_def_count_2grams.json',\n",
    "    'models/config/lr/lr_l1_tfidf_2grams.json',\n",
    "    'models/config/lr/lr_l2_tfidf_2grams.json',\n",
    "    'models/config/nb/nb_def_binary_2grams.json',\n",
    "    'models/config/svm/svm_def_binary_2grams.json',\n",
    "    'models/config/svm/svm_def_count_2grams.json',\n",
    "    'models/config/svm/svm_def_tfidf_2grams.json'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = {}\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "    for cfg_file in models:\n",
    "\n",
    "        model_cfg = ConfigLoader.load_config(cfg_file)\n",
    "        print('Processing', model_cfg['name'])\n",
    "\n",
    "        vectorizer_cls = model_cfg['vectorizer_class']\n",
    "        vectorizer = eval(vectorizer_cls)(\n",
    "            tokenizer_cfg=model_cfg['tokenizer'],\n",
    "            vectorizer_cfg=model_cfg['vectorizer'],\n",
    "            tfidf=model_cfg['tfidf']\n",
    "        )\n",
    "\n",
    "        results = {}\n",
    "        for split_key, split in sorted(splits.items()):\n",
    "            # split data\n",
    "            train_ids = list(split['train']) + list(split['dev'])\n",
    "            test_ids = list(split['test'])\n",
    "            X_train, X_test = X[train_ids], X[test_ids]\n",
    "            y_train, y_test = y[train_ids], y[test_ids]\n",
    "            # vectorize data\n",
    "            X_train, X_test = vectorizer.vectorize(X_train, X_test)\n",
    "            y_train = np.array(y_train)\n",
    "            y_test = np.array(y_test)\n",
    "            # train & test model\n",
    "            model = eval(model_cfg['model_class'])(model_cfg['model'])\n",
    "            results[split_key] = model.train_test(X_train, X_test, y_train, y_test)\n",
    "\n",
    "        all_results[model_cfg['name']] = {\n",
    "            k: v for k, v in Metrics.average_results(results)['split_avg'].items()\n",
    "            if k.startswith('test_')\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    'models/config/cnn/cnn_100d_234x100.json',\n",
    "    'models/config/rnn/rnn_100d_1x32x1.json',\n",
    "    'models/config/rnn/rnn_100d_1x32x2.json',\n",
    "    'models/config/lstm/lstm_100d_1x32x1.json',\n",
    "    'models/config/lstm/lstm_100d_1x32x2.json'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_paths(model_cfg, root):\n",
    "    if model_cfg['network']['pretrained_embeddings'] is not None:\n",
    "        cache_path = os.path.join(root, model_cfg['dataloader_params']['vector_cache'])\n",
    "        embed_path = os.path.join(root, model_cfg['network']['pretrained_embeddings'])\n",
    "        model_cfg['network']['pretrained_embeddings'] = embed_path\n",
    "        model_cfg['dataloader_params']['embeddings_path'] = embed_path\n",
    "        model_cfg['dataloader_params']['vector_cache'] = cache_path\n",
    "    model_cfg['save_directory'] = os.path.join(root, model_cfg['save_directory'])\n",
    "    return model_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = {}\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "    for cfg_file in models:\n",
    "\n",
    "        model_cfg = ConfigLoader.load_config(cfg_file)\n",
    "        print('Processing', model_cfg['name'])\n",
    "        \n",
    "        if model_cfg['name'] not in best_models:\n",
    "            best_models[model_cfg['name']] = {}\n",
    "        \n",
    "        # correct paths\n",
    "        model_cfg = correct_paths(model_cfg, root)\n",
    "        \n",
    "        # create dated directory for saving model\n",
    "        save_directory = FileUtils.mkdir_timed(model_cfg['save_directory'], datetime.now(), model_cfg['name'])\n",
    "\n",
    "        results = {}\n",
    "        for split_key, split in sorted(splits.items()):\n",
    "            if model_cfg['resume_from'] is None:\n",
    "                curr_dir = os.path.join(save_directory, f'{split_key}')\n",
    "                model_cfg['save_directory'] = curr_dir\n",
    "            # split data\n",
    "            train_loader, dev_loader, test_loader, vocab = DatasetWrapper.iters(\n",
    "                X, y, split, **model_cfg['dataloader_params']\n",
    "            )\n",
    "            # train & test model\n",
    "            model_cls = eval(model_cfg['model_class'])\n",
    "            trainer_cls = eval(model_cfg['trainer_class'])\n",
    "            model = model_cls(model_cfg, vocab)\n",
    "            model.summary()\n",
    "            trainer = trainer_cls.initialize(\n",
    "                model, model_cfg, model_cfg['resume_from']\n",
    "            )\n",
    "            trainer.train(train_loader, dev_loader)\n",
    "\n",
    "            # evaluate\n",
    "            best_model_path = trainer.best_model_path()\n",
    "            best_models[model_cfg['name']][split_key] = best_model_path\n",
    "            model = model_cls(model_cfg, vocab)\n",
    "            evaluator = trainer_cls.initialize(model, model_cfg, best_model_path)\n",
    "            split_results = {'train_{}'.format(k): v for k, v in evaluator.evaluate(train_loader)[0].items()}\n",
    "            split_results.update({'val_{}'.format(k): v for k, v in evaluator.evaluate(dev_loader)[0].items()})\n",
    "            split_results.update({'test_{}'.format(k): v for k, v in evaluator.evaluate(test_loader)[0].items()})\n",
    "            split_results['epoch'] = evaluator.checkpoint_epoch\n",
    "            results[split_key] = split_results\n",
    "\n",
    "        all_results[model_cfg['name']] = {\n",
    "            k: v for k, v in Metrics.average_results(results)['split_avg'].items()\n",
    "            if k.startswith('test_')\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(all_results, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# uncomment for report\n",
    "# for m_name, m_res in all_results.items():\n",
    "#     print(f'{m_name} & {m_res[\"test_precision\"]:.4f} & {m_res[\"test_recall\"]:.4f} & {m_res[\"test_f_score\"]:.4f} & {m_res[\"test_accuracy\"]/100:.4f} \\\\\\\\')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_id = 3\n",
    "model_cfg_pth = 'models/config/cnn/cnn_100d_234x100.json'\n",
    "model_best = best_models['cnn_100d_234x100'][split_id]\n",
    "print(f'Best model path:\\n{model_best}')\n",
    "model_cfg = ConfigLoader.load_config(model_cfg_pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare test data\n",
    "# 0 -- true, 1 -- false/misleading\n",
    "test_data = [\n",
    "    (1, 'Flu vaccine are the main reason for COVID-19.'), \n",
    "    (1, 'West loses race to develop COVID-19 vaccine. The Russian vaccine against COVID-19 is ready.'),\n",
    "    (0, 'CDC says to wear two masks to help flatten the case curve.')\n",
    "]\n",
    "\n",
    "y_test, X_test = zip(*test_data)\n",
    "\n",
    "y_test = np.array(y_test)\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "np.info(y_test)\n",
    "\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing cnn_100d_234x100\n",
      "Using CNN, CNNTrainer\n",
      "\n",
      "Results:\n",
      "========\n",
      "{\n",
      "    \"n_samples\": 3,\n",
      "    \"pos_samples\": 2,\n",
      "    \"neg_samples\": 1,\n",
      "    \"correct\": 3,\n",
      "    \"accuracy\": 1.0,\n",
      "    \"precision\": 1.0,\n",
      "    \"recall\": 1.0,\n",
      "    \"f_score\": 1.0,\n",
      "    \"tn\": 1,\n",
      "    \"tp\": 2,\n",
      "    \"fn\": 0,\n",
      "    \"fp\": 0,\n",
      "    \"loss\": 0.40968477725982666\n",
      "}\n",
      "Predictions:\n",
      "============\n",
      "Predicted label: 1\n",
      "True label: 1\n",
      "Text: West loses race to develop COVID-19 vaccine. The Russian vaccine against COVID-19 is ready.\n",
      "\n",
      "Predicted label: 0\n",
      "True label: 0\n",
      "Text: CDC says to wear two masks to help flatten the case curve.\n",
      "\n",
      "Predicted label: 1\n",
      "True label: 1\n",
      "Text: Flu vaccine are the main reason for COVID-19.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "    print('Processing', model_cfg['name'])\n",
    "\n",
    "    # turn off saving\n",
    "    model_cfg['save_best'] = False\n",
    "\n",
    "    # correct paths\n",
    "    model_cfg = correct_paths(model_cfg, root)\n",
    "\n",
    "    # create dated directory for saving model\n",
    "    save_directory = FileUtils.mkdir_timed(model_cfg['save_directory'], datetime.now(), model_cfg['name'])\n",
    "    \n",
    "    # use original vocab\n",
    "    _, _, _, vocab = DatasetWrapper.iters(X, y, splits[split_id], **model_cfg['dataloader_params'])\n",
    "\n",
    "    # split data\n",
    "    split = {'train': [0, 1, 2], 'dev': [0, 1, 2], 'test': [0, 1, 2]}\n",
    "    train_loader, dev_loader, test_loader, _ = DatasetWrapper.iters(\n",
    "        X_test, y_test, split, **model_cfg['dataloader_params']\n",
    "    )\n",
    "\n",
    "    # load model\n",
    "    model_cls = eval(model_cfg['model_class'])\n",
    "    trainer_cls = eval(model_cfg['trainer_class']) \n",
    "    print(f'Using {model_cls.__name__}, {trainer_cls.__name__}\\n')\n",
    "    model = model_cls(model_cfg, vocab)\n",
    "    evaluator = trainer_cls.initialize(model, model_cfg, model_best)\n",
    "    \n",
    "    # pass data through model and print results\n",
    "    print('Results:')\n",
    "    print('=' * len('results:'))\n",
    "    results = evaluator.evaluate(test_loader)\n",
    "    print(json.dumps(results[0], indent=4))\n",
    "    print('Predictions:')\n",
    "    print('=' * len('predictions:'))\n",
    "    for batch in train_loader:\n",
    "        for text, true, predicted in zip(batch.raw, batch.label, results[1]):\n",
    "            print(f'Predicted label: {predicted}')\n",
    "            print(f'True label: {true}')\n",
    "            print(f'Text: {text}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
